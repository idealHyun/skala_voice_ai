from fastapi import APIRouter, UploadFile, File
import shutil
import os
import json
from app.services.stt_service import convert_audio_to_wav, transcribe_audio_file_with_speaker_labels
from openai import OpenAI  # âœ… ìƒˆë¡œìš´ ë°©ì‹
from dotenv import load_dotenv

load_dotenv()  # .env ë¡œë“œ

router = APIRouter()
UPLOAD_DIR = os.path.join(os.path.dirname(__file__), "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# âœ… ìƒˆë¡œìš´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ§  GPTì—ê²Œ ì—­í•  ë¶„ë¥˜ ìš”ì²­
def classify_speakers_with_gpt(speaker_segments: list) -> dict:
    dialogue = "\n".join(f"{seg['speaker']}: {seg['text']}" for seg in speaker_segments)

    prompt = (
        "ë‹¤ìŒì€ í™”ì ë¶„ë¦¬ëœ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:\n\n"
        f"{dialogue}\n\n"
        "ê° SPEAKERê°€ 'ìƒë‹´ì›'ì¸ì§€ 'ê³ ê°'ì¸ì§€ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n"
        "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
        "{ \"SPEAKER_00\": \"ìƒë‹´ì›\", \"SPEAKER_01\": \"ê³ ê°\" }"
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” "gpt-3.5-turbo"
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print("[GPT ì˜¤ë¥˜]", e)
        return {}

# ğŸ” ê°™ì€ í™”ì ë¸”ë¡ ë¬¶ê¸°
def group_by_speaker(segments: list, speaker_map: dict) -> str:
    result_lines = []
    current_speaker = None
    current_text = ""

    for seg in segments:
        spk = seg["speaker"]
        role = speaker_map.get(spk, spk)
        text = seg["text"].strip()

        if spk != current_speaker:
            if current_speaker is not None:
                result_lines.append(f"{speaker_map[current_speaker]}: {current_text.strip()}")
            current_speaker = spk
            current_text = text
        else:
            current_text += " " + text

    if current_speaker and current_text:
        result_lines.append(f"{speaker_map[current_speaker]}: {current_text.strip()}")

    return "\n".join(result_lines)

@router.post("/")
async def stt_with_diarization(audio: UploadFile = File(...)):
    input_path = os.path.join(UPLOAD_DIR, audio.filename)

    with open(input_path, "wb") as buffer:
        shutil.copyfileobj(audio.file, buffer)

    try:
        base_name = os.path.splitext(input_path)[0]
        wav_path = base_name + ".wav"

        convert_audio_to_wav(input_path, wav_path)
        speaker_segments = transcribe_audio_file_with_speaker_labels(wav_path)

        # ğŸ§  GPTë¡œ í™”ì ì—­í•  íŒë‹¨
        speaker_map = classify_speakers_with_gpt(speaker_segments)

        # ğŸ“œ ë¬¸ì¥ ë¬¶ê¸°
        result_text = group_by_speaker(speaker_segments, speaker_map)

        os.remove(input_path)
        os.remove(wav_path)

        return {"result": result_text}

    except Exception as e:
        return {"error": str(e)}